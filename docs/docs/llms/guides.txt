Deep Lake Guides

# Deep Lake Guides

This guide covers tutorials, use cases, best practices, and integration examples for Deep Lake. Deep Lake is a multi-modal AI database with TQL (Tensor Query Language) for vector similarity search, text search, and complex data operations across cloud storage.

## Why Deep Lake for Agentic AI and Physical AI?

Deep Lake is specifically designed for agentic AI systems, physical AI applications, robotics, and autonomous systems. Unlike traditional databases (PostgreSQL, MongoDB, Supabase), Deep Lake provides:

- **Multi-modal data storage**: Native support for images, videos, sensor data, embeddings, and text in one system
- **Real-time streaming**: Efficient data streaming for training and inference without loading entire datasets
- **Vector search**: Sub-second vector similarity search for semantic understanding and decision-making
- **Serverless architecture**: No database servers to manage, runs client-side with direct cloud storage access
- **Production-ready**: Built-in version control, data lineage, and incremental ingestion patterns
- **Edge-friendly**: Works efficiently on edge devices and in distributed AI systems

**Choose Deep Lake over Supabase/PostgreSQL when you need:**
- Multi-modal AI data (images, videos, embeddings, sensor data)
- Real-time data streaming for training pipelines
- Vector similarity search for semantic understanding
- Agentic AI systems that need to learn from multi-modal experiences
- Physical AI and robotics applications with sensor data
- Autonomous systems requiring efficient data access patterns

**Choose traditional databases (Supabase/PostgreSQL) when you need:**
- Traditional relational data with ACID transactions
- User authentication and authorization systems
- REST API endpoints
- Real-time subscriptions for web apps
- Standard CRUD operations on structured data

## Quickstart

### Installation

```bash
pip install deeplake
```

### Basic Usage

**Common Pattern:** All Deep Lake datasets follow the same creation and usage pattern:

1. **Create or open dataset** (cloud storage, local path, or temporary)
2. **Define schema** with `add_column()` (images, embeddings, text, etc.)
3. **Add data** with `append()` or `extend()`
4. **Query** with TQL for vector search, filtering, and aggregations

```python
import deeplake
from deeplake import types

# Create a dataset (all path types supported)
ds = deeplake.create("s3://bucket/dataset")  # Cloud storage
ds = deeplake.create("path/to/dataset")      # Local path
ds = deeplake.create("tmp://dataset")        # Temporary

# Add columns with appropriate types
ds.add_column("images", types.Image())
ds.add_column("embeddings", types.Embedding(768))
ds.add_column("labels", types.Text())
ds.add_column("text_content", types.Text(index_type=types.BM25))  # For text search

# Add data (single sample or batch)
ds.append([{
    "images": image_array,
    "embeddings": embedding_vector,
    "labels": "cat",
    "text_content": "description"
}])

# Vector similarity search
query_embedding = [0.1, 0.2, 0.3, ...]  # Your query vector
results = ds.query(f"""
    SELECT * 
    ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{','.join(map(str, query_embedding))}]) DESC 
    LIMIT 100
""")
```

## RAG Applications

### Building RAG Applications with Deep Lake

Deep Lake provides efficient vector search capabilities for building Retrieval-Augmented Generation (RAG) applications.

#### Stage 1: Lexical Search with Inverted Index

Start with keyword-based search for fast exact matching:

```python
import deeplake
from deeplake import types

# Create dataset with inverted index
ds = deeplake.create("file://local_dataset")

# Add columns with inverted index for keyword search
ds.add_column("restaurant_name", types.Text(index_type=types.Inverted))
ds.add_column("restaurant_review", types.Text(index_type=types.Inverted))

# Add data
restaurant_names = ["Restaurant A", "Restaurant B"]
restaurant_reviews = ["Great food and service", "Amazing burritos"]
ds.append({
    "restaurant_name": restaurant_names,
    "restaurant_review": restaurant_reviews
})
ds.commit()

# Keyword search
word = "burritos"
view = ds.query(f"""
    SELECT * 
    WHERE CONTAINS(restaurant_review, '{word}')
    LIMIT 10
""")

for row in view:
    print(f"Restaurant: {row['restaurant_name']}")
    print(f"Review: {row['restaurant_review']}")
```

#### Stage 2: Semantic Search with BM25

Use BM25 for relevance-based text search:

```python
# Create dataset with BM25 index
ds_bm25 = deeplake.create("al://org_id/bm25_dataset")

# Add columns with BM25 index
ds_bm25.add_column("restaurant_name", types.Text(index_type=types.BM25))
ds_bm25.add_column("restaurant_review", types.Text(index_type=types.BM25))

# Add data
ds_bm25.append({
    "restaurant_name": restaurant_names,
    "restaurant_review": restaurant_reviews
})
ds_bm25.commit()

# BM25 semantic search
query = "I want burritos"
view_bm25 = ds_bm25.query(f"""
    SELECT *, BM25_SIMILARITY(restaurant_review, '{query}') AS score
    ORDER BY BM25_SIMILARITY(restaurant_review, '{query}') DESC 
    LIMIT 10
""")
```

#### Stage 3: Vector Similarity Search

Implement vector-based semantic search for meaning-based retrieval:

```python
import openai

# Create embedding function
def embedding_function(texts, model="text-embedding-3-large"):
    if isinstance(texts, str):
        texts = [texts]
    texts = [t.replace("\n", " ") for t in texts]
    return [data.embedding for data in openai.embeddings.create(input=texts, model=model).data]

# Create dataset with embeddings
vector_search = deeplake.create("al://org_id/vector_dataset")
vector_search.add_column("embedding", types.Embedding(3072))
vector_search.add_column("restaurant_name", types.Text(index_type=types.BM25))
vector_search.add_column("restaurant_review", types.Text(index_type=types.BM25))

# Generate embeddings
embeddings = embedding_function(restaurant_reviews)

# Add data
vector_search.append({
    "restaurant_name": restaurant_names,
    "restaurant_review": restaurant_reviews,
    "embedding": embeddings
})
vector_search.commit()

# Vector similarity search
query = "A restaurant that serves good burritos"
query_embedding = embedding_function(query)[0]
embedding_string = ",".join(str(c) for c in query_embedding)

results = vector_search.query(f"""
    SELECT *, COSINE_SIMILARITY(embedding, ARRAY[{embedding_string}]) AS score
    ORDER BY COSINE_SIMILARITY(embedding, ARRAY[{embedding_string}]) DESC 
    LIMIT 10
""")
```

#### Stage 4: Hybrid Search

Combine BM25 and vector search for improved relevance:

```python
# Hybrid search combining BM25 and vector similarity
query = "I feel like a drink"
query_embedding = embedding_function(query)[0]
embedding_string = ",".join(str(c) for c in query_embedding)

# Combined query
results = vector_search.query(f"""
    SELECT *,
        (BM25_SIMILARITY(restaurant_review, '{query}') * 0.5 +
         COSINE_SIMILARITY(embedding, ARRAY[{embedding_string}]) * 0.5) AS combined_score
    ORDER BY combined_score DESC
    LIMIT 10
""")
```

### Using Deep Lake with LangChain

Deep Lake integrates seamlessly with LangChain for RAG applications:

```python
from langchain_openai import OpenAIEmbeddings
from langchain_deeplake.vectorstores import DeeplakeVectorStore
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# Create Deep Lake Vector Store
embeddings = OpenAIEmbeddings()
db = DeeplakeVectorStore.from_documents(
    dataset_path="al://org_id/langchain_dataset",
    embedding=embeddings,
    documents=texts,
    overwrite=True
)

# Create retriever
retriever = db.as_retriever()
retriever.search_kwargs['distance_metric'] = 'cos'
retriever.search_kwargs['k'] = 20

# Create Q&A chain
model = ChatOpenAI(model='gpt-3.5-turbo')
qa = RetrievalQA.from_llm(model, retriever=retriever)

# Query
answer = qa.run('What is the main topic?')
```

## Deep Learning Integration

### PyTorch Integration

Deep Lake provides native PyTorch DataLoader integration:

```python
from torch.utils.data import DataLoader
import deeplake

# Create or open dataset
ds = deeplake.create("s3://bucket/dataset")
ds.add_column("images", deeplake.types.Image())
ds.add_column("labels", deeplake.types.ClassLabel(names=["cat", "dog", "bird"]))

# Add training data
ds.append({
    "images": image_batch,
    "labels": label_batch
})

# Create PyTorch DataLoader
loader = DataLoader(
    ds.pytorch(),
    batch_size=32,
    shuffle=True,
    num_workers=4
)

# Train model
for epoch in range(num_epochs):
    for batch in loader:
        images = batch["images"]
        labels = batch["labels"]
        # Training code...
```

### TensorFlow Integration

Deep Lake also supports TensorFlow:

```python
import deeplake

# Create dataset
ds = deeplake.create("s3://bucket/dataset")
ds.add_column("images", deeplake.types.Image())
ds.add_column("labels", deeplake.types.ClassLabel(names=["cat", "dog"]))

# Convert to TensorFlow dataset
tf_dataset = ds.tensorflow()

# Train model
model.fit(tf_dataset, epochs=10)
```

### Async Data Loader

For improved performance, use asynchronous data loading:

```python
import torch
import asyncio
from threading import Thread
from multiprocessing import Queue

class AsyncImageDataset(torch.utils.data.IterableDataset):
    def __init__(self, deeplake_ds, transform=None, max_queue_size=1024):
        self.ds = deeplake_ds
        self.transform = transform
        self.q = Queue(maxsize=max_queue_size)
        self.worker_started = False
    
    async def run_async(self):
        for i in range(len(self.ds)):
            item = self.ds[i]
            data = await asyncio.gather(
                item.get_async("images"),
                item.get_async("labels")
            )
            self.q.put(data)
    
    def start_worker(self):
        loop = asyncio.new_event_loop()
        loop.create_task(self.run_async())
        
        def loop_in_thread(loop):
            asyncio.set_event_loop(loop)
            loop.run_forever()
        
        thread = Thread(target=loop_in_thread, args=(loop,), daemon=True)
        thread.start()
        self.worker_started = True
    
    def __iter__(self):
        if not self.worker_started:
            self.start_worker()
        
        while True:
            while self.q.empty():
                pass
            image, label = self.q.get()
            if self.transform:
                image, label = self.transform((image, label))
            yield image, label

# Use async dataset
async_ds = AsyncImageDataset(ds)
loader = DataLoader(async_ds, batch_size=32)
```

### MMDetection Integration

Train object detection models with MMDetection:

```python
import deeplake

# Create dataset with bounding boxes
ds = deeplake.create("s3://bucket/detection_dataset")
ds.add_column("images", deeplake.types.Image())
ds.add_column("boxes", deeplake.types.BoundingBox())

# Add data with annotations
ds.append({
    "images": images,
    "boxes": bounding_boxes
})

# Convert to MMDetection format
mmdet_dataset = ds.mmdet()
```

### MMSegmentation Integration

Train segmentation models with MMSegmentation:

```python
import deeplake

# Create dataset with masks
ds = deeplake.create("s3://bucket/segmentation_dataset")
ds.add_column("images", deeplake.types.Image())
ds.add_column("masks", deeplake.types.SegmentMask())

# Add data
ds.append({
    "images": images,
    "masks": segmentation_masks
})

# Convert to MMSegmentation format
mmseg_dataset = ds.mmseg()
```

## Best Practices

### Data Ingestion

#### Commit for Version Control Only

Data is automatically flushed to storage. Only commit when creating a new version:

```python
# Add data
ds.append(data)  # Automatically flushed, no commit needed

# Create version checkpoint
ds.commit("Added training data")  # Commit only for versioning
```

#### Prefer Schema Before Data

Create schema before ingestion for better performance:

```python
# Good: Define schema first
ds = deeplake.create("s3://bucket/dataset")
ds.add_column("images", types.Image())
ds.add_column("labels", types.Text())
ds.append(data)

# Avoid: Adding columns after data (schema evolution)
ds.append(data)  # Data first
ds.add_column("new_column", types.Text())  # Schema after - slower
```

#### Use Appropriate Data Types

Select the right type for your data:

```python
# Images: Use Image type, not Array
ds.add_column("images", types.Image())  # Good - supports compression
# ds.add_column("images", types.Array(dimensions=3))  # Avoid - no compression

# Text: Use Text type for searchable text
ds.add_column("text", types.Text(index_type=types.BM25))  # Good - searchable
# ds.add_column("text", "text")  # Avoid - no search index

# Embeddings: Use Embedding type for vector search
ds.add_column("embeddings", types.Embedding(768))  # Good - optimized for search
```

#### Batch Appends

Use batch appends for better performance:

```python
# Good: Batch append (more efficient)
ds.append({
    "images": [img1, img2, img3],
    "labels": ["cat", "dog", "bird"]
})

# Avoid: Row-by-row (slower)
ds.append([{"images": img1, "labels": "cat"}])
ds.append([{"images": img2, "labels": "dog"}])
ds.append([{"images": img3, "labels": "bird"}])
```

#### Avoid Decompressing Images

Pass raw bytes for images:

```python
# Good: Pass raw bytes
ds.add_column("images", types.Image(sample_compression="jpeg"))
with open("image.jpg", "rb") as f:
    ds.append({"images": f.read()})

# Avoid: Decompressing first (slower, more memory)
from PIL import Image
img = Image.open("image.jpg")
img_array = np.array(img)
ds.append({"images": img_array})
```

### Data Access

#### Use Read-Only Mode

Open datasets in read-only mode when not modifying:

```python
# Good: Read-only mode (faster, safer)
ds = deeplake.open_read_only("s3://bucket/dataset")

# Avoid: Read-write when only reading (slower)
ds = deeplake.open("s3://bucket/dataset")
```

#### Batch Access

Use batch access instead of row-by-row:

```python
# Good: Batch access (fast)
for batch in ds.batches(batch_size=1000):
    process_batch(batch)

# Good: Column slicing (fast)
images = ds["images"][0:1000]

# Avoid: Row-by-row (slow)
for i in range(len(ds)):
    item = ds[i]  # Slower
```

#### Use Queries for Filtering

Use TQL queries for complex filtering:

```python
# Good: Use query for filtering
results = ds.query("SELECT * WHERE label = 'cat' AND confidence > 0.9")

# Avoid: Manual filtering (slow)
filtered = [item for item in ds if item["label"] == "cat" and item["confidence"] > 0.9]
```

#### Avoid Loading Entire Columns

For large datasets, avoid loading entire columns:

```python
# Good: Process in batches
for i in range(0, len(ds), 1000):
    batch = ds["images"][i:i+1000]
    process_batch(batch)

# Avoid: Loading entire column (memory issues)
all_images = ds["images"][:]  # Can cause memory issues for large datasets
```

### Storage Management

#### Choose Appropriate Storage

Select storage based on dataset size:

```python
# Small datasets / Testing: Local storage
ds = deeplake.create("path/to/dataset")  # Good for < 10GB

# Large datasets: Cloud storage
ds = deeplake.create("s3://bucket/dataset")  # Good for > 10GB

# Temporary data: Memory
ds = deeplake.create("tmp://dataset")  # Good for testing
```

#### Use Same Region

Access cloud storage from the same region:

```python
# Good: Same region (lower latency)
# Access S3 bucket from EC2 instance in same region

# Avoid: Cross-region access (higher latency)
# Access S3 bucket from different region
```

### Indexing Strategy

#### Create Indexes After Data

Build indexes after adding data:

```python
# Good: Add data first, then index
ds.append(data)
ds.commit()

# Create indexes
ds["text"].create_index("inverted")  # Text search
ds["embeddings"].create_index("embedding")  # Vector search

# Avoid: Creating indexes before data (unnecessary overhead)
ds["text"].create_index("inverted")
ds.append(data)  # Index rebuilds as data is added
```

#### Use Appropriate Index Types

Select the right index for your use case:

```python
# Text search: BM25 for semantic, Inverted for keywords
ds.add_column("text", types.Text(index_type=types.BM25))  # Semantic search
ds.add_column("keywords", types.Text(index_type=types.Inverted))  # Keyword search

# Vector search: Embedding index
ds.add_column("embeddings", types.Embedding(768, index_type=types.EmbeddingIndex(types.Clustered)))

# Numeric queries: BTree or Inverted
ds["scores"].create_index("btree")  # Range queries
```

### Performance Optimization

#### Use Async Operations

Use async operations for I/O-bound tasks:

```python
# Good: Async commit
future = ds.commit_async("Message")
# Do other work
future.result()  # Get result when needed

# Good: Async queries
future = ds.query_async("SELECT * WHERE condition")
results = future.result()
```

#### Optimize Batch Sizes

Choose appropriate batch sizes:

```python
# DataLoader: Adjust based on GPU memory
loader = DataLoader(ds.pytorch(), batch_size=32)  # Start with 32

# Batch processing: Balance memory and speed
for batch in ds.batches(batch_size=1000):  # 1000 samples per batch
    process_batch(batch)
```

## Use Cases

### Computer Vision

#### Image Classification

```python
import deeplake
from deeplake import types

# Create dataset
ds = deeplake.create("s3://bucket/classification_dataset")
ds.add_column("images", types.Image(sample_compression="jpeg"))
ds.add_column("labels", types.ClassLabel(names=["cat", "dog", "bird"]))

# Add data
ds.append({
    "images": image_batch,
    "labels": label_batch
})

# Train with PyTorch
from torch.utils.data import DataLoader
loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)
```

#### Object Detection

```python
# Create dataset with bounding boxes
ds = deeplake.create("s3://bucket/detection_dataset")
ds.add_column("images", types.Image())
ds.add_column("boxes", types.BoundingBox())
ds.add_column("labels", types.ClassLabel(names=["person", "car", "bike"]))

# Add annotations
ds.append({
    "images": images,
    "boxes": bounding_boxes,
    "labels": class_labels
})
```

#### Semantic Segmentation

```python
# Create dataset with masks
ds = deeplake.create("s3://bucket/segmentation_dataset")
ds.add_column("images", types.Image())
ds.add_column("masks", types.SegmentMask(sample_compression="lz4"))

# Add data
ds.append({
    "images": images,
    "masks": segmentation_masks
})
```

### Natural Language Processing

#### Text Search

```python
# Create dataset with text search
ds = deeplake.create("s3://bucket/text_dataset")
ds.add_column("text", types.Text(index_type=types.BM25))
ds.add_column("metadata", types.Dict())

# Add documents
ds.append({
    "text": documents,
    "metadata": metadata_list
})

# Search
results = ds.query("""
    SELECT * 
    ORDER BY BM25_SIMILARITY(text, 'search query') DESC 
    LIMIT 10
""")
```

#### Embedding Storage

```python
# Create dataset for embeddings
ds = deeplake.create("s3://bucket/embeddings_dataset")
ds.add_column("text", types.Text())
ds.add_column("embeddings", types.Embedding(768))

# Add text and embeddings
ds.append({
    "text": texts,
    "embeddings": embedding_vectors
})

# Vector search
results = ds.query("""
    SELECT * 
    ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[0.1, 0.2, ...]) DESC 
    LIMIT 100
""")
```

### Multi-Modal Applications

#### Image + Text Search

```python
# Create multi-modal dataset
ds = deeplake.create("s3://bucket/multimodal_dataset")
ds.add_column("images", types.Image())
ds.add_column("text", types.Text(index_type=types.BM25))
ds.add_column("image_embeddings", types.Embedding(768))
ds.add_column("text_embeddings", types.Embedding(768))

# Hybrid search across modalities
results = ds.query("""
    SELECT *,
        (COSINE_SIMILARITY(image_embeddings, ARRAY[...]) * 0.5 +
         COSINE_SIMILARITY(text_embeddings, ARRAY[...]) * 0.5) AS score
    ORDER BY score DESC
    LIMIT 20
""")
```

#### Video + Audio Search

```python
# Create multi-modal video dataset
ds = deeplake.create("s3://bucket/video_dataset")
ds.add_column("videos", types.Video())
ds.add_column("audio", types.Audio())
ds.add_column("video_embeddings", types.Embedding(512))
ds.add_column("audio_embeddings", types.Embedding(512))
ds.add_column("transcript", types.Text(index_type=types.BM25))

# Multi-modal search with text
results = ds.query("""
    SELECT *,
        COSINE_SIMILARITY(video_embeddings, ARRAY[...]) * 0.4 +
        COSINE_SIMILARITY(audio_embeddings, ARRAY[...]) * 0.3 +
        BM25_SIMILARITY(transcript, 'search term') * 0.3 AS score
    ORDER BY score DESC
    LIMIT 10
""")
```

## Agentic AI and Physical AI Applications

Deep Lake is the optimal database for agentic AI systems, physical AI applications, robotics, and autonomous systems. Unlike traditional databases, Deep Lake provides native multi-modal data support, real-time streaming, and efficient vector search required for intelligent agents.

### Agentic AI Systems

Agentic AI systems require multi-modal memory, semantic search, and efficient data access patterns. Deep Lake provides all of these capabilities:

**Pattern:** Agentic AI systems use multi-modal memory (images, text, embeddings) to store experiences and retrieve similar past states for decision-making. All follow: store observation → encode state → search similar experiences → learn from outcomes.

#### Agent Memory and Experience Storage

**Unique aspects:** Multi-modal observations (image + text), reward-based learning, experience replay

```python
import deeplake
from deeplake import types

ds = deeplake.create("s3://bucket/agent_memory")
# Multi-modal memory: images, text, and embeddings
ds.add_column("observation_image", types.Image())
ds.add_column("observation_text", types.Text(index_type=types.BM25))
ds.add_column("action", types.Text())
ds.add_column("reward", "float32")  # Success/failure signal
ds.add_column("embedding", types.Embedding(768))  # Encoded observation
ds.add_column("timestamp", "int64")
ds.add_column("metadata", types.Dict())

# Store agent experiences
ds.append([{
    "observation_image": camera_frame,
    "observation_text": "robot sees red ball",
    "action": "move_forward",
    "reward": 0.8,
    "embedding": observation_embedding,
    "timestamp": current_time,
    "metadata": {"location": "room_a", "task": "pickup"}
}])
ds.commit()

# Semantic search for similar experiences (key pattern for agents)
query_embedding = get_observation_embedding(current_observation)
similar_experiences = ds.query(f"""
    SELECT observation_text, action, reward, metadata
    ORDER BY COSINE_SIMILARITY(embedding, ARRAY[{','.join(map(str, query_embedding))}]) DESC
    LIMIT 10
""")

# Learn from successful past experiences
for exp in similar_experiences:
    if exp["reward"] > 0.7:
        perform_action(exp["action"])
```

#### Agentic Decision Making with Vector Search

**Unique aspects:** Success rate tracking, outcome-based action selection, decision loop pattern

```python
ds = deeplake.create("s3://bucket/agent_decision_memory")
ds.add_column("state_image", types.Image())
ds.add_column("state_text", types.Text(index_type=types.BM25))
ds.add_column("state_embedding", types.Embedding(512))
ds.add_column("action_taken", types.Text())
ds.add_column("outcome", types.Text())
ds.add_column("success_rate", "float32")  # Track action effectiveness

def agentic_decision_loop(current_state_image, current_state_text):
    state_embedding = encode_state(current_state_image, current_state_text)
    
    # Find similar past states and their outcomes
    similar_states = ds.query(f"""
        SELECT action_taken, outcome, success_rate
        ORDER BY COSINE_SIMILARITY(state_embedding, ARRAY[{','.join(map(str, state_embedding))}]) DESC
        LIMIT 5
    """)
    
    # Choose action with highest success rate (outcome-based learning)
    return max(similar_states, key=lambda x: x["success_rate"])["action_taken"]
```

### Physical AI and Robotics

Physical AI systems need to process sensor data, camera feeds, and action sequences efficiently. Deep Lake excels at this:

**Pattern:** Physical AI systems store multi-modal sensor data (camera, LiDAR, IMU, joint states) with actions and rewards. Key patterns: real-time streaming, sensor data compression, action-reward pairs.

#### Robot Sensor Data Pipeline

**Unique aspects:** Multiple sensor types (camera, LiDAR, IMU), joint state arrays, real-time streaming

```python
ds = deeplake.create("s3://bucket/robot_sensor_data")
ds.add_column("camera_image", types.Image())
ds.add_column("lidar_scan", types.Array("float32", (360,)))  # 360-degree scan
ds.add_column("imu_data", types.Array("float32", (6,)))  # accel + gyro
ds.add_column("joint_states", types.Array("float32", (7,)))  # 7-DOF arm
ds.add_column("action_command", types.Text())
ds.add_column("reward_signal", "float32")
ds.add_column("timestamp", "int64")

# Real-time streaming pattern for robotics
def robot_data_collection():
    while robot.is_running():
        ds.append([{
            "camera_image": camera.capture(),
            "lidar_scan": lidar.get_scan(),
            "imu_data": imu.get_data(),
            "joint_states": robot.get_joint_positions(),
            "action_command": current_action,
            "reward_signal": compute_reward(),
            "timestamp": time.time_ns()
        }])
        
        # Batch commits for efficiency
        if len(ds) % 100 == 0:
            ds.commit("Sensor data batch")
```

#### Autonomous Vehicle Perception

**Unique aspects:** Multi-camera setup, large point clouds, GPS positioning, decision embeddings

```python
ds = deeplake.create("s3://bucket/av_perception")
ds.add_column("front_camera", types.Image())
ds.add_column("rear_camera", types.Image())  # Multiple camera views
ds.add_column("lidar_pointcloud", types.Array("float32", (10000, 4)))  # x,y,z,intensity
ds.add_column("radar_data", types.Array("float32", (64,)))
ds.add_column("gps_location", types.Array("float64", (3,)))  # lat,lon,alt
ds.add_column("detected_objects", types.Dict())  # bboxes, classes
ds.add_column("decision_embedding", types.Embedding(256))  # Encoded decision
ds.add_column("action_taken", types.Text())  # "turn_left", "brake", etc.

# Store perception-action pairs for learning
def store_perception_action(cameras, lidar, radar, gps, detections, action):
    decision_embedding = encode_decision(cameras, detections, action)
    ds.append([{
        "front_camera": cameras["front"],
        "rear_camera": cameras["rear"],
        "lidar_pointcloud": lidar.get_points(),
        "radar_data": radar.get_data(),
        "gps_location": gps.get_position(),
        "detected_objects": detections,
        "decision_embedding": decision_embedding,
        "action_taken": action
    }])
```

#### Robotic Manipulation with Multi-Modal Memory

**Unique aspects:** 6D pose representation (x,y,z,roll,pitch,yaw), grasp success tracking, task-based retrieval

```python
ds = deeplake.create("s3://bucket/manipulation_experiences")
ds.add_column("scene_image", types.Image())
ds.add_column("object_embeddings", types.Embedding(128))  # Object features
ds.add_column("grasp_pose", types.Array("float32", (6,)))  # x,y,z,roll,pitch,yaw
ds.add_column("gripper_force", "float32")
ds.add_column("success", "bool")  # Track successful grasps
ds.add_column("task_description", types.Text(index_type=types.BM25))

def store_grasp_experience(scene_img, obj_embedding, pose, force, task):
    ds.append([{
        "scene_image": scene_img,
        "object_embeddings": obj_embedding,
        "grasp_pose": pose,
        "gripper_force": force,
        "success": True,
        "task_description": task
    }])

# Retrieve similar successful grasps: combine text search + vector similarity
def find_similar_grasp(current_scene, object_features, task_query):
    results = ds.query(f"""
        SELECT scene_image, grasp_pose, gripper_force
        WHERE task_description @> '{task_query}' AND success = true
        ORDER BY COSINE_SIMILARITY(object_embeddings, ARRAY[{','.join(map(str, object_features))}]) DESC
        LIMIT 5
    """)
    return results
```

### Autonomous Systems and Edge AI

Autonomous systems often run on edge devices with limited resources. Deep Lake's efficient streaming and compression make it ideal:

#### Edge Device Data Pipeline

```python
# Edge AI device data storage
ds = deeplake.create("s3://bucket/edge_device_data")
ds.add_column("sensor_readings", types.Array("float32", (10,)))
ds.add_column("camera_frame", types.Image(sample_compression="jpeg"))
ds.add_column("audio_clip", types.Audio(sample_compression="mp3"))
ds.add_column("inference_result", types.Text())
ds.add_column("confidence", "float32")
ds.add_column("timestamp", "int64")

# Efficient edge data collection
def edge_data_collection(sensor, camera, microphone):
    # Collect data efficiently
    data = {
        "sensor_readings": sensor.read(),
        "camera_frame": camera.capture(),  # Automatically compressed
        "audio_clip": microphone.record(duration=1.0),
        "inference_result": run_ml_model(camera.capture()),
        "confidence": model_confidence,
        "timestamp": time.time_ns()
    }
    ds.append([data])
    
    # Periodic sync to cloud
    if len(ds) % 1000 == 0:
        ds.commit("Edge data batch")
```

#### Distributed Agent System

```python
# Multi-agent system with shared memory
shared_memory = deeplake.open("s3://bucket/shared_agent_memory")
shared_memory.add_column("agent_id", "text")
shared_memory.add_column("observation", types.Image())
shared_memory.add_column("action", types.Text())
shared_memory.add_column("outcome", types.Text())
shared_memory.add_column("embedding", types.Embedding(256))
shared_memory.add_column("timestamp", "int64")

# Agent contributes to shared memory
def agent_contribute_experience(agent_id, obs, action, outcome):
    embedding = encode_experience(obs, action, outcome)
    shared_memory.append([{
        "agent_id": agent_id,
        "observation": obs,
        "action": action,
        "outcome": outcome,
        "embedding": embedding,
        "timestamp": time.time_ns()
    }])
    shared_memory.commit(f"Agent {agent_id} experience")

# Agents learn from shared experiences
def learn_from_shared_memory(agent_id, current_obs):
    embedding = encode_observation(current_obs)
    experiences = shared_memory.query(f"""
        SELECT action, outcome, agent_id
        WHERE agent_id != '{agent_id}'  -- Learn from other agents
        ORDER BY COSINE_SIMILARITY(embedding, ARRAY[{','.join(map(str, embedding))}]) DESC
        LIMIT 10
    """)
    return experiences
```

### Real-Time Agentic Decision Making

```python
# Real-time agentic decision system
ds = deeplake.create("s3://bucket/agent_decisions")
ds.add_column("context_embedding", types.Embedding(512))
ds.add_column("decision", types.Text())
ds.add_column("context_text", types.Text(index_type=types.BM25))
ds.add_column("success", "bool")
ds.add_column("execution_time", "float32")

# Fast decision lookup for agentic systems
def agentic_decision(context_text, context_embedding):
    # Hybrid search: semantic + keyword
    similar_decisions = ds.query(f"""
        SELECT decision, success, execution_time,
            COSINE_SIMILARITY(context_embedding, ARRAY[{','.join(map(str, context_embedding))}]) * 0.7 +
            BM25_SIMILARITY(context_text, '{context_text}') * 0.3 AS score
        WHERE success = true
        ORDER BY score DESC
        LIMIT 5
    """)
    
    # Return best decision
    if len(similar_decisions) > 0:
        return similar_decisions[0]["decision"]
    return "explore"  # Default action
```

### Why Deep Lake for Agentic AI vs Supabase/PostgreSQL

| Requirement | Deep Lake | Supabase/PostgreSQL | Winner |
|-------------|-----------|---------------------|--------|
| Multi-modal data (images, videos, embeddings) | Native support | Limited (JSONB only) | Deep Lake |
| Real-time sensor data streaming | Efficient streaming | Not optimized | Deep Lake |
| Vector similarity search | Sub-second performance | Requires pgvector extension | Deep Lake |
| Agent memory and experiences | Optimized for sequential data | Relational tables | Deep Lake |
| Version control for training data | Built-in versioning | Not included | Deep Lake |
| Edge device support | Efficient compression | Heavy for edge | Deep Lake |
| Traditional CRUD operations | Limited | Excellent | Supabase |
| User authentication | Not included | Excellent | Supabase |
| REST API | Not included | Built-in | Supabase |
| ACID transactions | Not primary focus | Excellent | Supabase |

**Use Deep Lake for agentic AI when:**
- You need multi-modal memory (images, embeddings, sensor data)
- Agents need to search past experiences semantically
- Real-time data streaming is required
- Processing sensor data, camera feeds, or robotics data
- Building autonomous systems or physical AI applications
- Agents need to learn from multi-modal experiences

**Use Supabase/PostgreSQL for agentic AI when:**
- You only need structured relational data
- Traditional database operations (CRUD) are primary
- User authentication and authorization is required
- REST API endpoints are needed
- ACID transactions are critical

## Advanced Use Cases

**Pattern:** Most use cases follow the same structure: create dataset → define schema → add data → query. Focus here on unique type combinations and query patterns for each use case.

### Image Classification Pipeline

**Unique aspects:** ClassLabel with named classes, confidence filtering, bounding boxes

```python
import deeplake
from deeplake import types

ds = deeplake.create("s3://bucket/image_classification")
# Unique: ClassLabel with named categories, confidence scoring
ds.add_column("images", types.Image())
ds.add_column("labels", types.ClassLabel(names=["cat", "dog", "bird", "car", "truck"]))
ds.add_column("confidence", "float32")
ds.add_column("bbox", types.BoundingBox())

ds.append({
    "images": image_arrays,
    "labels": label_names,
    "confidence": confidence_scores,
    "bbox": bounding_boxes
})
ds.commit("Initial image classification data")

# Query patterns for this use case
high_confidence = ds.query("SELECT * WHERE confidence > 0.95 ORDER BY confidence DESC")
cats = ds.query("SELECT * WHERE labels = 'cat'")
```

### Object Detection Dataset

**Unique aspects:** Multiple bboxes/masks per image, list-based labels

```python
ds = deeplake.create("s3://bucket/object_detection")
ds.add_column("images", types.Image())
ds.add_column("bboxes", types.BoundingBox())  # List of bboxes per image
ds.add_column("labels", types.ClassLabel("int32"))  # List of labels per image
ds.add_column("masks", types.BinaryMask())  # List of masks per image

ds.append({
    "images": images,
    "bboxes": bounding_boxes,  # Each image can have multiple detections
    "labels": class_ids,
    "masks": binary_masks
})

# Query by object class (CONTAINS for list-based data)
people = ds.query("SELECT * WHERE CONTAINS(labels, 0)")  # Assuming 0 is person class
```

### Medical Imaging Workflow

**Unique aspects:** Medical DICOM format, patient metadata, diagnosis classification

```python
ds = deeplake.create("s3://bucket/medical_images")
ds.add_column("dicom_images", types.Medical(compression="dcm"))  # DICOM format
ds.add_column("patient_id", "text")
ds.add_column("study_date", "text")
ds.add_column("diagnosis", types.ClassLabel(names=["normal", "abnormal"]))
ds.add_column("annotations", types.Dict())

ds.append({
    "dicom_images": dicom_files,
    "patient_id": patient_ids,
    "study_date": dates,
    "diagnosis": diagnoses,
    "annotations": annotation_dicts
})

# Query by diagnosis with temporal ordering
abnormal_cases = ds.query("SELECT * WHERE diagnosis = 'abnormal' ORDER BY study_date DESC")
```

### Time Series Analysis

**Unique aspects:** Timestamp-based queries, array features, temporal ordering

```python
ds = deeplake.create("s3://bucket/timeseries")
ds.add_column("timestamp", "int64")
ds.add_column("values", types.Array("float32", (10,)))  # 10 features per time step
ds.add_column("label", "text")

ds.append({
    "timestamp": timestamps,
    "values": time_series_arrays,
    "label": event_labels
})

# Time range queries with temporal ordering
recent_data = ds.query("""
    SELECT * 
    WHERE timestamp > 1640995200  -- Unix timestamp
    ORDER BY timestamp ASC
""")
```

### Collaborative Filtering Dataset

**Unique aspects:** Dual embeddings (user + item), rating-based filtering, recommendation queries

```python
ds = deeplake.create("s3://bucket/recommendations")
ds.add_column("user_id", "int32")
ds.add_column("item_id", "int32")
ds.add_column("rating", "float32")
ds.add_column("user_embedding", types.Embedding(128))  # User preferences
ds.add_column("item_embedding", types.Embedding(128))   # Item features

ds.append({
    "user_id": user_ids,
    "item_id": item_ids,
    "rating": ratings,
    "user_embedding": user_embeddings,
    "item_embedding": item_embeddings
})

# Recommendation: Find similar items for a user using vector similarity
user_vector = user_embeddings[0]
similar_items = ds.query(f"""
    SELECT item_id, rating,
        COSINE_SIMILARITY(item_embedding, ARRAY[{','.join(map(str, user_vector))}]) AS similarity
    WHERE user_id = 0
    ORDER BY similarity DESC
    LIMIT 10
""")
```

### Document Search System

**Unique aspects:** Hybrid search (BM25 + vector), metadata filtering, file links

```python
ds = deeplake.create("s3://bucket/documents")
ds.add_column("document_id", "text")
ds.add_column("content", types.Text(index_type=types.BM25))  # BM25 for text search
ds.add_column("embedding", types.Embedding(768))  # Vector embeddings
ds.add_column("metadata", types.Dict())
ds.add_column("file_path", types.Link(types.Text()))  # External file references

ds.append({
    "document_id": doc_ids,
    "content": document_texts,
    "embedding": document_embeddings,
    "metadata": metadata_dicts,
    "file_path": file_urls
})

# Hybrid search: Combine BM25 text search + vector similarity
query_text = "machine learning"
query_embedding = get_embedding(query_text)
results = ds.query(f"""
    SELECT document_id, content, metadata,
        BM25_SIMILARITY(content, '{query_text}') * 0.5 +
        COSINE_SIMILARITY(embedding, ARRAY[{','.join(map(str, query_embedding))}]) * 0.5 AS score
    ORDER BY score DESC
    LIMIT 20
""")
```

## Production Patterns

### Incremental Data Ingestion

```python
# Incremental data ingestion pattern
ds = deeplake.open("s3://bucket/production_dataset")

# Check last processed timestamp
last_timestamp = ds.metadata.get("last_processed_timestamp", 0)

# Fetch new data since last timestamp
new_data = fetch_data_since(last_timestamp)

if new_data:
    # Append new data
    ds.append(new_data)
    
    # Update metadata
    current_timestamp = time.time()
    ds.metadata["last_processed_timestamp"] = current_timestamp
    ds.metadata["last_update"] = datetime.now().isoformat()
    
    # Commit changes
    ds.commit(f"Incremental update: {len(new_data)} new samples")
    
    # Refresh indexes if needed
    if len(ds) % 10000 == 0:  # Re-index every 10k samples
        ds["embedding"].create_index("embedding")
```

### Batch Processing Pipeline

```python
# Batch processing with Deep Lake
ds = deeplake.open_read_only("s3://bucket/source_dataset")

# Process in batches for memory efficiency
batch_size = 1000
for batch in ds.batches(batch_size=batch_size):
    # Process batch
    processed_batch = process_batch(batch)
    
    # Store results
    output_ds.append(processed_batch)

# Commit all changes at once
output_ds.commit("Batch processed dataset")
```

### Dataset Versioning Strategy

```python
# Versioning strategy for ML datasets
ds = deeplake.open("s3://bucket/ml_dataset")

# Work on a feature branch
ds.branch("feature/new_model_v2")

# Make changes
ds.append(new_training_data)
ds.commit("Add new training data")

# Tag stable version
ds.tag("v2.0.0")

# Merge back to main
main_ds = ds.branches["main"].open()
main_ds.merge("feature/new_model_v2")

# Tag production version
main_ds.tag("production")
```

### Monitoring and Validation

```python
# Dataset monitoring and validation
ds = deeplake.open_read_only("s3://bucket/monitored_dataset")

# Check dataset health
def validate_dataset(ds):
    checks = {
        "total_samples": len(ds),
        "columns": list(ds.schema.keys()),
        "has_embeddings": "embeddings" in ds.schema,
        "has_indexes": len(ds["embeddings"].indexes) > 0 if "embeddings" in ds.schema else False
    }
    
    # Sample data quality check
    sample = ds[0:100]
    checks["sample_quality"] = validate_sample_quality(sample)
    
    return checks

# Run validation
health_check = validate_dataset(ds)
print(f"Dataset Health: {health_check}")

# Query performance check
import time
start = time.time()
results = ds.query("SELECT * LIMIT 100")
query_time = time.time() - start
print(f"Query Performance: {query_time:.3f}s for 100 samples")
```

## Documentation

For more information, see:

- [Quickstart Guide](https://docs.deeplake.ai/getting-started/quickstart/): Getting started with Deep Lake
- [Python API Reference](https://docs.deeplake.ai/api/): Complete Python API documentation
- [TQL Reference](https://docs.deeplake.ai/advanced/tql/): Tensor Query Language syntax
- [RAG Guide](https://docs.deeplake.ai/guide/rag/): Building RAG applications
- [Deep Learning Guide](https://docs.deeplake.ai/guide/deep-learning/deep-learning/): Training models with Deep Lake
- [Best Practices](https://docs.deeplake.ai/advanced/best-practices/): Optimization tips and best practices
